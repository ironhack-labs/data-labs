{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing APIs Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Now we will take a look on a real data. When you parse data from web you will often meet API based web-pages. \n",
    "\n",
    "For example [zalando.fr](https://www.zalando.fr/accueil-homme/) is API based web-page. \n",
    "\n",
    "In this guided lab you will learn how to obtain the links from webpages and extract the data. Read through this doc, execute the cells in order and make sure you understand the explanations. \n",
    "\n",
    "*Note: This guided lab uses Google Chrome. Other browsers like Safari and Firefox have similar tools for developers but they work differently. To save your time in following this lab, it is strongly recommended that you install and use Google Chrome.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the link\n",
    "\n",
    "Zalando is discount e-store where you can buy clothes and accesories with discount. When we go to the web-page, we can choose different sections. First the general process will be shown using [Children section](https://www.zalando.fr/accueil-enfant/) as example.\n",
    "\n",
    "Here we will parse data about promotions only. Therefore, final output will be the DataFrame with all the goods under discount.\n",
    "\n",
    "[![Image from Gyazo](https://i.gyazo.com/fa4874d8e81c7570273bbfb853d66308.png)](https://gyazo.com/fa4874d8e81c7570273bbfb853d66308)\n",
    "\n",
    "\n",
    "We go to Promos page. Right click of mouse shows us a list of actions possible, from which we select Inspect.\n",
    "\n",
    "<img src='https://i.gyazo.com/bccbd11d69c9040dc98758d443e32052.png' width=\"400\">\n",
    "\n",
    "\n",
    "You will see the menu dropdown on the right side or on the bottom of the window. There you should click on Network:\n",
    "\n",
    "\n",
    "[![Image from Gyazo](https://i.gyazo.com/f7e0db81cbfee67694183d1a7640bf81.png)](https://gyazo.com/f7e0db81cbfee67694183d1a7640bf81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after the developer part will change showing the files behind the page. In order to obtain only useful files we select the following settings:\n",
    "1. Preserve Log\n",
    "2. Select XHR files.\n",
    "\n",
    "[![Image from Gyazo](https://i.gyazo.com/9a899d4441d9d93e795f79747f1e47d5.png)](https://gyazo.com/9a899d4441d9d93e795f79747f1e47d5)\n",
    "\n",
    "In order to obtain some files we need to scrool down and go forward to second page. \n",
    "\n",
    "[![Image from Gyazo](https://i.gyazo.com/0956eb3d5125075a236c9a439c7749c7.png)](https://gyazo.com/0956eb3d5125075a236c9a439c7749c7)\n",
    "\n",
    "In the Network panel you can see the following files being uploaded. All the data on the web-page is uploaded from the json file, which is one of the following. It is important to understand which file contains what kind of information. \n",
    "\n",
    "<a href=\"https://gyazo.com/cf97a655869f0b22df0ada1cb2a41c3c\"><img src=\"https://i.gyazo.com/cf97a655869f0b22df0ada1cb2a41c3c.png\" alt=\"Image from Gyazo\" width=\"724.8\"/></a>\n",
    "\n",
    "When you find what kind of information you need for the data to be uploaded you just test it. Here we need the article... file:\n",
    "\n",
    "<a href=\"https://gyazo.com/78b35bf492994b3f35c0564a21da202a\"><img src=\"https://i.gyazo.com/78b35bf492994b3f35c0564a21da202a.png\" alt=\"Image from Gyazo\" width=\"727.2\"/></a>\n",
    "\n",
    "When we test the link in Chrome inkognito mode we obtain the proper json file:\n",
    "\n",
    "\n",
    "<a href=\"https://gyazo.com/b60453fa98454fa29771c731a5174443\"><img src=\"https://i.gyazo.com/b60453fa98454fa29771c731a5174443.png\" alt=\"Image from Gyazo\" width=\"1530.4\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to change the objects in the json file (kind of pagination), you need to change the offset (the number of the first element on the page). in fact, if you take a look on the link, it is easy to unerstand the structure of the link.\n",
    "\n",
    "# Reading the data\n",
    "\n",
    "Now the party rocks! When we know how can we obtain the data, it is not a problem to obtain the whole database with all the data from the web-page.\n",
    "In this lab you will collect your database of Zalando products. You select which goods you want to track. You can define as many filters to your data as you want. Just make sure that the data represents the filters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the url you obtained for your data\n",
    "url='https://www.zalando.fr/api/catalog/articles?categories=promo-enfant&limit=84&offset=84&sort=sale'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect first 84 object of the of the data (1st page)\n",
    "\n",
    "Your output should be a Pandas DataFrame of goods. Each row should contain only text or numbers, having *family_articles, flags, media* and *sizes* remaining lists (they are exceptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "response = requests.get(url)\n",
    "results = response.json()\n",
    "results\n",
    "\n",
    "\n",
    "flattened_data = json_normalize(results)\n",
    "\n",
    "flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "flattened_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect all the objects from selected filters. Total number of pages can be found in the same json. Use *sku* column as index.\n",
    "\n",
    "Your output should be a Pandas DataFrame of goods. Each row should contain only text or numbers, having family_articles, flags, media and sizes remaining lists (they are exceptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of pages\n",
    "total_pages=results['pagination']['page_count']\n",
    "\n",
    "# Your code\n",
    "df=pd.DataFrame()\n",
    "for i in range(total_pages):\n",
    "    k=84*i\n",
    "    url=f'https://www.zalando.fr/api/catalog/articles?categories=promo-enfant&limit=84&offset={k}&sort=sale'\n",
    "    response = requests.get(url)\n",
    "    results = response.json()\n",
    "    flattened_data = json_normalize(results)\n",
    "    flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "    flattened_data1=flattened_data1.set_index('sku')\n",
    "    df = df.append(flattened_data1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending brand in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.brand_name.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the brand with maximal total discount (sum of discounts on all goods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data is still text. Convert prices into numbers:\n",
    "df['price.original']=df['price.original'].str.extract('(\\d*,\\d*)')\n",
    "df['price.promotional']=df['price.promotional'].str.extract('(\\d*,\\d*)')\n",
    "\n",
    "df['price.original'] = [x.replace(',', '.') for x in df['price.original']]\n",
    "df['price.promotional'] = [x.replace(',', '.') for x in df['price.promotional']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discount_amount']=df['price.original'].astype(float)-df['price.promotional'].astype(float)\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disc=df1.groupby(['brand_name']).sum().discount_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disc.sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the brands without discount at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disc[total_disc==0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
