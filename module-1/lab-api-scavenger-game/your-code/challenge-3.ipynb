{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3: Hidden Cold Joke\n",
    "Using Python, call Github API to find out the cold joke contained in the 24 secret files in the following repo:\n",
    "\n",
    "https://github.com/ironhack-datalabs/scavenger\n",
    "\n",
    "The filenames of the secret files contain .scavengerhunt and they are scattered in different directories of this repo. The secret files are named from .0001.scavengerhunt to .0024.scavengerhunt. They are scattered randomly throughout this repo. You need to search for these files by calling the Github API, not searching the local files on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credentials\n",
    "path = '/Users/josematos/Documents/github_credentials'\n",
    "sys.path.insert(0, path)\n",
    "from credentials import username, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing url contents and transform it to DataFrame\n",
    "url = 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents'\n",
    "login = requests.get(url, auth=(username,token))\n",
    "results = login.json()\n",
    "data = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting list of URL\n",
    "name_lst = [col for col in data['path']]\n",
    "url_lst = ['https://api.github.com/repos/ironhack-datalabs/scavenger/contents/'+name for name in name_lst]\n",
    "del url_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening each folder in the Scavenger Repo\n",
    "all_files = []\n",
    "for url in url_lst:\n",
    "    url1 = url\n",
    "    login1 = requests.get(url1, auth=(username,token)).json()\n",
    "    results = pd.DataFrame(login1)\n",
    "    all_files.append(results)    \n",
    "files_data = pd.concat(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the data\n",
    "scavenger_data =  files_data[(files_data['size']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizing the Data to sort it by something meaningful\n",
    "sort_by_name = scavenger_data.sort_values('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of URL to open the files\n",
    "scavenger_lst = [x for x in sort_by_name['download_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In data science 80 percent of time spent is preparing data 20 percent of time is spent complaining about the need to prepare data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening Each file\n",
    "lst_words = []\n",
    "for a in scavenger_lst:\n",
    "    login2 = requests.get(a, auth=(username,token))\n",
    "    soup =BeautifulSoup(login2.text,'html.parser')\n",
    "    lst_words.append(str(soup))\n",
    "lst_words = [re.compile('[\\W_]+').sub('',text) for text in lst_words] #Cleaning the list\n",
    "#Creating sentecne\n",
    "sentence = ' '.join(lst_words)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 'https://raw.githubusercontent.com/ironhack-datalabs/scavenger/master/98750/.0001.scavengerhunt'\n",
    "# login2 = requests.get(a, auth=(username,token))\n",
    "# soup =BeautifulSoup(login2.text,'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url1 = 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/15024'\n",
    "# login1 = requests.get(url1, auth=(username,token))\n",
    "\n",
    "# results1 = login1.json()\n",
    "# results1\n",
    "# data1 = pd.DataFrame(results1)\n",
    "# data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
