{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Web Scraping Lab\n",
    "\n",
    "In this lab you will first learn the following code snippet which is a simple web spider class that allows you to scrape paginated webpages. Read the code, run it, and make sure you understand how it work. In the challenges of this lab, we will guide you in building up this class so that eventually you will have a more robus web spider that you can further work on in the Web Scraping Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<title>Quotes to Scrape</title>\\n    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\\n    <link rel=\"stylesheet\" href=\"/static/main.css\">\\n</head>\\n<body>\\n    <div class=\"container\">\\n        <div class=\"row header-box\">\\n            <div class=\"col-md-8\">\\n                <h1>\\n                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\\n                </h1>\\n            </div>\\n            <div class=\"col-md-4\">\\n                <p>\\n                \\n                    <a href=\"/login\">Login</a>\\n                \\n                </p>\\n            </div>\\n        </div>\\n    \\n\\n<div class=\"row\">\\n    <div class=\"col-md-8\">\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"change,deep-thoughts,thinking,world\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\\n            \\n            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\\n            \\n            <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\\n            \\n            <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cIt is our choices, Harry, that show what we truly are, far more than our abilities.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\\n        <a href=\"/author/J-K-Rowling\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"abilities,choices\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\\n            \\n            <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\\n            \\n            <a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\\n            \\n            <a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\\n            \\n            <a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\\n        <a href=\"/author/Jane-Austen\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"aliteracy,books,classic,humor\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\\n            \\n            <a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\\n            \\n            <a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\\n            \\n            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cImperfection is beauty, madness is genius and it&#39;s better to be absolutely ridiculous than absolutely boring.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\\n        <a href=\"/author/Marilyn-Monroe\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"be-yourself,inspirational\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cTry not to become a man of success. Rather become a man of value.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"adulthood,success,value\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\\n            \\n            <a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\\n            \\n            <a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cIt is better to be hated for what you are than to be loved for what you are not.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Andr\\xc3\\xa9 Gide</small>\\n        <a href=\"/author/Andre-Gide\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"life,love\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\\n            \\n            <a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cI have not failed. I&#39;ve just found 10,000 ways that won&#39;t work.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\\n        <a href=\"/author/Thomas-A-Edison\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\\n            \\n            <a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n            <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cA woman is like a tea bag; you never know how strong it is until it&#39;s in hot water.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\\n        <a href=\"/author/Eleanor-Roosevelt\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"misattributed-eleanor-roosevelt\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cA day without sunshine is like, you know, night.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\\n        <a href=\"/author/Steve-Martin\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"humor,obvious,simile\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\\n            \\n            <a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\\n            \\n            <a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\\n            \\n        </div>\\n    </div>\\n\\n    <nav>\\n        <ul class=\"pager\">\\n            \\n            \\n            <li class=\"next\">\\n                <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\\n            </li>\\n            \\n        </ul>\\n    </nav>\\n    </div>\\n    <div class=\"col-md-4 tags-box\">\\n        \\n            <h2>Top Ten tags</h2>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 28px\" href=\"/tag/love/\">love</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/inspirational/\">inspirational</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/life/\">life</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 24px\" href=\"/tag/humor/\">humor</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 22px\" href=\"/tag/books/\">books</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 14px\" href=\"/tag/reading/\">reading</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 10px\" href=\"/tag/friendship/\">friendship</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/friends/\">friends</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/truth/\">truth</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 6px\" href=\"/tag/simile/\">simile</a>\\n            </span>\\n            \\n        \\n    </div>\\n</div>\\n\\n    </div>\\n    <footer class=\"footer\">\\n        <div class=\"container\">\\n            <p class=\"text-muted\">\\n                Quotes by: <a href=\"https://www.goodreads.com/quotes\">GoodReads.com</a>\\n            </p>\\n            <p class=\"copyright\">\\n                Made with <span class=\\'sh-red\\'>\\xe2\\x9d\\xa4</span> by <a href=\"https://scrapinghub.com\">Scrapinghub</a>\\n            </p>\\n        </div>\\n    </footer>\\n</body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs # added this alias myself, check the code for other mentions of BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    return content\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1 - Custom Parser Function\n",
    "\n",
    "In this challenge, complete the custom `quotes_parser()` function so that the returned result contains the quote string instead of the whole html page content.\n",
    "\n",
    "In the cell below, write your updated `quotes_parser()` function and kickstart the spider. Make sure the results being printed contain a list of quote strings extracted from the html content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    # this function scrapes the url, and parses the content\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "    \n",
    "    \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_quotes_parser)\n",
    "my_spider.kickstart() # part of this function prints itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 - Error Handling\n",
    "\n",
    "In `IronhackSpider.scrape_url()`, catch any error that might occur when you make requests to scrape the webpage. This includes checking the response status code and catching http request errors such as timeout, SSL, and too many redirects.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "    \n",
    "    \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_quotes_parser)\n",
    "my_spider.kickstart() # part of this function prints itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Sleep Interval\n",
    "\n",
    "In `IronhackSpider.kickstart()`, implement `sleep_interval`. You will check if `self.sleep_interval` is larger than 0. If so, tell the FOR loop to sleep the given amount of time before making the next request.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    # CHALLENGE 3 - integrate a sleep timer\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            if self.sleep_interval > 0: \n",
    "                sleep(sleep_interval) # do I need to pass 'self.sleep_interval' as the argument instead?\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "    \n",
    "    \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_quotes_parser)\n",
    "my_spider.kickstart() # part of this function prints itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Test Batch Scraping\n",
    "\n",
    "Change the `PAGES_TO_SCRAPE` value from `1` to `10`. Try if your code still works as intended to scrape 10 webpages. If there are errors in your code, fix them.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n",
      "Response Status Code is 200\n",
      "[\"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', \"“If you can't explain it to a six year old, you don't understand it yourself.”\", \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', '“Life is what happens to us while we are making other plans.”']\n",
      "Response Status Code is 200\n",
      "['“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”', '“For every minute you are angry you lose sixty seconds of happiness.”', '“If you judge people, you have no time to love them.”', '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', '“Today you are You, that is truer than true. There is no one alive who is Youer than You.”', '“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”', '“It is impossible to live without failing at something, unless you live so cautiously that you might as well not have lived at all - in which case, you fail by default.”', '“Logic will get you from A to Z; imagination will get you everywhere.”', '“One good thing about music, when it hits you, you feel no pain.”']\n",
      "Response Status Code is 200\n",
      "[\"“The more that you read, the more things you will know. The more that you learn, the more places you'll go.”\", '“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?”', '“The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.”', '“Not all of us can do great things. But we can do small things with great love.”', '“To the well-organized mind, death is but the next great adventure.”', \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", \"“We read to know we're not alone.”\", '“Any fool can know. The point is to understand.”', '“I have always imagined that Paradise will be a kind of library.”', '“It is never too late to be what you might have been.”']\n",
      "Response Status Code is 200\n",
      "['“A reader lives a thousand lives before he dies, said Jojen. The man who never reads lives only one.”', '“You can never get a cup of tea large enough or a book long enough to suit me.”', '“You believe lies so you eventually learn to trust no one but yourself.”', '“If you can make a woman laugh, you can make her do anything.”', '“Life is like riding a bicycle. To keep your balance, you must keep moving.”', '“The real lover is the man who can thrill you by kissing your forehead or smiling into your eyes or just staring into space.”', \"“A wise girl kisses but doesn't love, listens but doesn't believe, and leaves before she is left.”\", '“Only in the darkness can you see the stars.”', '“It matters not what someone is born, but what they grow to be.”', '“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”']\n",
      "Response Status Code is 200\n",
      "['“There is nothing I would not do for those who are really my friends. I have no notion of loving people by halves, it is not my nature.”', '“Do one thing every day that scares you.”', '“I am good, but not an angel. I do sin, but I am not the devil. I am just a small girl in a big world trying to find someone to love.”', '“If I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.”', '“If you only read the books that everyone else is reading, you can only think what everyone else is thinking.”', '“The difference between genius and stupidity is: genius has its limits.”', \"“He's like a drug for you, Bella.”\", '“There is no friend as loyal as a book.”', '“When one door of happiness closes, another opens; but often we look so long at the closed door that we do not see the one which has been opened for us.”', \"“Life isn't about finding yourself. Life is about creating yourself.”\"]\n",
      "Response Status Code is 200\n",
      "[\"“That's the problem with drinking, I thought, as I poured myself a drink. If something bad happens you drink in an attempt to forget; if something good happens you drink in order to celebrate; and if nothing happens you drink to make something happen.”\", '“You don’t forget the face of the person who was your last hope.”', \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", '“To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.”', '“Not all those who wander are lost.”', '“Do not pity the dead, Harry. Pity the living, and, above all those who live without love.”', '“There is nothing to writing. All you do is sit down at a typewriter and bleed.”', '“Finish each day and be done with it. You have done what you could. Some blunders and absurdities no doubt crept in; forget them as soon as you can. Tomorrow is a new day. You shall begin it serenely and with too high a spirit to be encumbered with your old nonsense.”', '“I have never let my schooling interfere with my education.”', \"“I have heard there are troubles of more than one kind. Some come from ahead and some come from behind. But I've bought a big bat. I'm all ready you see. Now my troubles are going to have troubles with me!”\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['“If I had a flower for every time I thought of you...I could walk through my garden forever.”', '“Some people never go crazy. What truly horrible lives they must lead.”', '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', \"“What really knocks me out is a book that, when you're all done reading it, you wish the author that wrote it was a terrific friend of yours and you could call him up on the phone whenever you felt like it. That doesn't happen much, though.”\", '“The reason I talk to myself is because I’m the only one whose answers I accept.”', \"“You may say I'm a dreamer, but I'm not the only one. I hope someday you'll join us. And the world will live as one.”\", '“I am free of all prejudice. I hate everyone equally. ”', \"“The question isn't who is going to let me; it's who is going to stop me.”\", \"“′Classic′ - a book which people praise and don't read.”\"]\n",
      "Response Status Code is 200\n",
      "['“Anyone who has never made a mistake has never tried anything new.”', \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", '“Remember, if the time should come when you have to make a choice between what is right and what is easy, remember what happened to a boy who was good, and kind, and brave, because he strayed across the path of Lord Voldemort. Remember Cedric Diggory.”', '“I declare after all there is no enjoyment like reading! How much sooner one tires of any thing than of a book! -- When I have a house of my own, I shall be miserable if I have not an excellent library.”', '“There are few people whom I really love, and still fewer of whom I think well. The more I see of the world, the more am I dissatisfied with it; and every day confirms my belief of the inconsistency of all human characters, and of the little dependence that can be placed on the appearance of merit or sense.”', '“Some day you will be old enough to start reading fairy tales again.”', '“We are not necessarily doubting that God will do the best for us; we are wondering how painful the best will turn out to be.”', '“The fear of death follows from the fear of life. A man who lives fully is prepared to die at any time.”', '“A lie can travel half way around the world while the truth is putting on its shoes.”', '“I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.”']\n",
      "Response Status Code is 200\n",
      "['“The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing, and should therefore be treated with great caution.”', \"“I'm the one that's got to die when it's time for me to die, so let me live my life the way I want to.”\", '“To die will be an awfully big adventure.”', '“It takes courage to grow up and become who you really are.”', '“But better to get hurt by the truth than comforted with a lie.”', '“You never really understand a person until you consider things from his point of view... Until you climb inside of his skin and walk around in it.”', '“You have to write the book that wants to be written. And if the book will be too difficult for grown-ups, then you write it for children.”', '“Never tell the truth to people who are not worthy of it.”', \"“A person's a person, no matter how small.”\", '“... a mind needs books as a sword needs a whetstone, if it is to keep its edge.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    # CHALLENGE 3 - integrate a sleep timer\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            if self.sleep_interval > 0: \n",
    "                sleep(sleep_interval) # do I need to pass 'self.sleep_interval' as the argument instead?\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 10 # how many webpages to scrape, updated for CHALLENGE 4\n",
    "    \n",
    "    \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_quotes_parser)\n",
    "my_spider.kickstart() # part of this function prints itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Scrape a Different Website\n",
    "\n",
    "Update the parameters passed to the `IronhackSpider` constructor so that you coder can crawl [books.toscrape.com](http://books.toscrape.com/). You will need to use a different `URL_PATTERN` (figure out the new url pattern by yourself) and write another parser function to be passed to `IronhackSpider`. \n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['A Light in the ...', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History ...', 'The Requiem Red', 'The Dirty Little Secrets ...', 'The Coming Woman: A ...', 'The Boys in the ...', 'The Black Maria', 'Starving Hearts (Triangular Trade ...', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little ...\", 'Rip it Up and ...', 'Our Band Could Be ...', 'Olio', 'Mesaerion: The Best Science ...', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n",
      "Response Status Code is 200\n",
      "['In Her Wake', 'How Music Works', 'Foolproof Preserving: A Guide ...', 'Chase Me (Paris Nights ...', 'Black Dust', 'Birdsong: A Story in ...', \"America's Cradle of Quarterbacks: ...\", 'Aladdin and His Wonderful ...', 'Worlds Elsewhere: Journeys Around ...', 'Wall and Piece', 'The Four Agreements: A ...', 'The Five Love Languages: ...', 'The Elephant Tree', 'The Bear and the ...', \"Sophie's World\", 'Penny Maybe', 'Maude (1883-1993):She Grew Up ...', 'In a Dark, Dark ...', 'Behind Closed Doors', \"You can't bury them ...\"]\n",
      "Response Status Code is 200\n",
      "['Slow States of Collapse: ...', 'Reasons to Stay Alive', 'Private Paris (Private #10)', '#HigherSelfie: Wake Up Your ...', 'Without Borders (Wanderlove #1)', 'When We Collided', 'We Love You, Charlie ...', 'Untitled Collection: Sabbath Poems ...', 'Unseen City: The Majesty ...', 'Unicorn Tracks', 'Unbound: How Eight Technologies ...', 'Tsubasa: WoRLD CHRoNiCLE 2 ...', 'Throwing Rocks at the ...', 'This One Summer', 'Thirst', 'The Torch Is Passed: ...', 'The Secret of Dreadwillow ...', 'The Pioneer Woman Cooks: ...', 'The Past Never Ends', 'The Natural History of ...']\n",
      "Response Status Code is 200\n",
      "['The Nameless City (The ...', 'The Murder That Never ...', 'The Most Perfect Thing: ...', 'The Mindfulness and Acceptance ...', 'The Life-Changing Magic of ...', 'The Inefficiency Assassin: Time ...', 'The Gutsy Girl: Escapades ...', 'The Electric Pencil: Drawings ...', 'The Death of Humanity: ...', 'The Bulletproof Diet: Lose ...', 'The Art Forger', 'The Age of Genius: ...', \"The Activist's Tao Te ...\", 'Spark Joy: An Illustrated ...', 'Soul Reader', 'Security', 'Saga, Volume 6 (Saga ...', 'Saga, Volume 5 (Saga ...', 'Reskilling America: Learning to ...', 'Rat Queens, Vol. 3: ...']\n",
      "Response Status Code is 200\n",
      "['Princess Jellyfish 2-in-1 Omnibus, ...', 'Princess Between Worlds (Wide-Awake ...', 'Pop Gun War, Volume ...', 'Political Suicide: Missteps, Peccadilloes, ...', 'Patience', 'Outcast, Vol. 1: A ...', 'orange: The Complete Collection ...', 'Online Marketing for Busy ...', 'On a Midnight Clear', 'Obsidian (Lux #1)', 'My Paris Kitchen: Recipes ...', 'Masks and Shadows', 'Mama Tried: Traditional Italian ...', 'Lumberjanes, Vol. 2: Friendship ...', 'Lumberjanes, Vol. 1: Beware ...', 'Lumberjanes Vol. 3: A ...', 'Layered: Baking, Building, and ...', 'Judo: Seven Steps to ...', 'Join', 'In the Country We ...']\n",
      "Response Status Code is 200\n",
      "['Immunity: How Elie Metchnikoff ...', 'I Hate Fairyland, Vol. ...', 'I am a Hero ...', 'How to Be Miserable: ...', 'Her Backup Boyfriend (The ...', 'Giant Days, Vol. 2 ...', 'Forever and Forever: The ...', 'First and First (Five ...', 'Fifty Shades Darker (Fifty ...', 'Everydata: The Misinformation Hidden ...', \"Don't Be a Jerk: ...\", 'Danganronpa Volume 1', 'Crown of Midnight (Throne ...', 'Codename Baboushka, Volume 1: ...', 'Camp Midnight', 'Call the Nurse: True ...', 'Burning', 'Bossypants', 'Bitch Planet, Vol. 1: ...', 'Avatar: The Last Airbender: ...']\n",
      "Response Status Code is 200\n",
      "['Algorithms to Live By: ...', 'A World of Flavor: ...', 'A Piece of Sky, ...', 'A Murder in Time', 'A Flight of Arrows ...', 'A Fierce and Subtle ...', 'A Court of Thorns ...', '(Un)Qualified: How God Uses ...', 'You Are What You ...', \"William Shakespeare's Star Wars: ...\", 'Tuesday Nights in 1980', 'Tracing Numbers on a ...', 'Throne of Glass (Throne ...', 'Thomas Jefferson and the ...', 'Thirteen Reasons Why', 'The White Cat and ...', 'The Wedding Dress', 'The Vacationers', 'The Third Wave: An ...', 'The Stranger']\n",
      "Response Status Code is 200\n",
      "['The Shadow Hero (The ...', 'The Secret (The Secret ...', 'The Regional Office Is ...', 'The Psychopath Test: A ...', 'The Project', 'The Power of Now: ...', \"The Omnivore's Dilemma: A ...\", 'The Nerdy Nummies Cookbook: ...', 'The Murder of Roger ...', 'The Mistake (Off-Campus #2)', \"The Matchmaker's Playbook (Wingmen ...\", 'The Love and Lemons ...', 'The Long Shadow of ...', 'The Kite Runner', 'The House by the ...', 'The Glittering Court (The ...', 'The Girl on the ...', 'The Genius of Birds', 'The Emerald Mystery', 'The Cookies & Cups ...']\n",
      "Response Status Code is 200\n",
      "['The Bridge to Consciousness: ...', \"The Artist's Way: A ...\", 'The Art of War', 'The Argonauts', 'The 10% Entrepreneur: Live ...', 'Suddenly in Love (Lake ...', 'Something More Than This', 'Soft Apocalypse', \"So You've Been Publicly ...\", 'Shoe Dog: A Memoir ...', 'Shobu Samurai, Project Aryoku ...', 'Secrets and Lace (Fatal ...', 'Scarlett Epstein Hates It ...', 'Romero and Juliet: A ...', 'Redeeming Love', 'Poses for Artists Volume ...', 'Poems That Make Grown ...', 'Nightingale, Sing', 'Night Sky with Exit ...', 'Mrs. Houdini']\n",
      "Response Status Code is 200\n",
      "['Modern Romance', 'Miss Peregrine’s Home for ...', 'Louisa: The Extraordinary Life ...', 'Little Red', 'Library of Souls (Miss ...', 'Large Print Heart of ...', 'I Had a Nice ...', 'Hollow City (Miss Peregrine’s ...', 'Grumbles', 'Full Moon over Noah’s ...', 'Frostbite (Vampire Academy #2)', 'Follow You Home', 'First Steps for New ...', 'Finders Keepers (Bill Hodges ...', 'Fables, Vol. 1: Legends ...', 'Eureka Trivia 6.0', 'Drive: The Surprising Truth ...', 'Done Rubbed Out (Reightman ...', 'Doing It Over (Most ...', 'Deliciously Ella Every Day: ...']\n",
      "Response Status Code is 200\n",
      "['Dark Notes', 'Daring Greatly: How the ...', 'Close to You', 'Chasing Heaven: What Dying ...', 'Big Magic: Creative Living ...', 'Becoming Wise: An Inquiry ...', 'Beauty Restored (Riley Family ...', 'Batman: The Long Halloween ...', 'Batman: The Dark Knight ...', \"Ayumi's Violin\", 'Anonymous', 'Amy Meets the Saints ...', 'Amid the Chaos', 'Amatus', 'Agnostic: A Spirited Manifesto', 'Zealot: The Life and ...', 'You (You #1)', 'Wonder Woman: Earth One, ...', 'Wild Swans', 'Why the Right Went ...']\n",
      "Response Status Code is 200\n",
      "['Whole Lotta Creativity Going ...', \"What's It Like in ...\", 'We Are Robin, Vol. ...', \"Walt Disney's Alice in ...\", 'V for Vendetta (V ...', 'Until Friday Night (The ...', 'Unbroken: A World War ...', 'Twenty Yawns', 'Through the Woods', 'This Is Where It ...', 'The Year of Magical ...', 'The Wright Brothers', 'The White Queen (The ...', 'The Wedding Pact (The ...', 'The Time Keeper', 'The Testament of Mary', 'The Star-Touched Queen', 'The Songs of the ...', 'The Song of Achilles', 'The Rosie Project (Don ...']\n",
      "Response Status Code is 200\n",
      "['The Power of Habit: ...', 'The Marriage of Opposites', 'The Lucifer Effect: Understanding ...', 'The Long Haul (Diary ...', 'The Loney', 'The Literature Book (Big ...', 'The Last Mile (Amos ...', 'The Immortal Life of ...', 'The Hidden Oracle (The ...', 'The Help Yourself Cookbook ...', 'The Guilty (Will Robie ...', 'The First Hostage (J.B. ...', 'The Dovekeepers', 'The Darkest Lie', 'The Bane Chronicles (The ...', 'The Bad-Ass Librarians of ...', 'The 14th Colony (Cotton ...', 'That Darkness (Gardiner and ...', 'Tastes Like Fear (DI ...', 'Take Me with You']\n",
      "Response Status Code is 200\n",
      "['Swell: A Year of ...', 'Superman Vol. 1: Before ...', 'Still Life with Bread ...', 'Steve Jobs', 'Sorting the Beef from ...', 'Someone Like You (The ...', 'So Cute It Hurts!!, ...', 'Shtum', 'See America: A Celebration ...', 'salt.', 'Robin War', 'Red Hood/Arsenal, Vol. 1: ...', 'Rain Fish', 'Quarter Life Poetry: Poems ...', 'Pet Sematary', 'Overload: How to Unplug, ...', 'Once Was a Time', 'Old School (Diary of ...', 'No Dream Is Too ...', 'Naruto (3-in-1 Edition), Vol. ...']\n",
      "Response Status Code is 200\n",
      "['My Name Is Lucy ...', 'My Mrs. Brown', 'My Kind of Crazy', 'Mr. Mercedes (Bill Hodges ...', 'More Than Music (Chasing ...', 'Made to Stick: Why ...', 'Luis Paints the World', 'Luckiest Girl Alive', 'Lowriders to the Center ...', 'Love Is a Mix ...', 'Looking for Lovely: Collecting ...', 'Living Leadership by Insight: ...', 'Let It Out: A ...', 'Lady Midnight (The Dark ...', \"It's All Easy: Healthy, ...\", 'Island of Dragons (Unwanteds ...', \"I Know What I'm ...\", 'I Am Pilgrim (Pilgrim ...', 'Hyperbole and a Half: ...', 'Hush, Hush (Hush, Hush ...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['Hold Your Breath (Search ...', 'Hamilton: The Revolution', 'Greek Mythic History', 'God: The Most Unpleasant ...', 'Glory over Everything: Beyond ...', 'Feathers: Displays of Brilliant ...', 'Far & Away: Places ...', 'Every Last Word', 'Eligible (The Austen Project ...', 'El Deafo', 'Eight Hundred Grapes', 'Eaternity: More than 150 ...', 'Eat Fat, Get Thin', \"Don't Get Caught\", 'Doctor Sleep (The Shining ...', 'Demigods & Magicians: Percy ...', 'Dear Mr. Knightley', 'Daily Fantasy Sports', 'Crazy Love: Overwhelmed by ...', 'Cometh the Hour (The ...']\n",
      "Response Status Code is 200\n",
      "['Code Name Verity (Code ...', 'Clockwork Angel (The Infernal ...', 'City of Glass (The ...', 'City of Fallen Angels ...', 'City of Bones (The ...', 'City of Ashes (The ...', 'Cell', 'Catching Jordan (Hundred Oaks)', 'Carry On, Warrior: Thoughts ...', 'Carrie', 'Buying In: The Secret ...', 'Brain on Fire: My ...', 'Batman: Europa', 'Barefoot Contessa Back to ...', 'Barefoot Contessa at Home: ...', 'Balloon Animals', 'Art Ops Vol. 1', 'Aristotle and Dante Discover ...', 'Angels Walking (Angels Walking ...', 'Angels & Demons (Robert ...']\n",
      "Response Status Code is 200\n",
      "['All the Light We ...', 'Adulthood Is a Myth: ...', 'Abstract City', 'A Time of Torment ...', 'A Study in Scarlet ...', 'A Series of Catastrophes ...', \"A People's History of ...\", 'A Man Called Ove', 'A Distant Mirror: The ...', 'A Brush of Wings ...', '1491: New Revelations of ...', 'The Three Searches, Meaning, ...', 'Searching for Meaning in ...', 'Rook', 'My Kitchen Year: 136 ...', '13 Hours: The Inside ...', \"Will You Won't You ...\", 'Tipping Point for Planet ...', 'The Star-Touched Queen', 'The Silent Sister (Riley ...']\n",
      "Response Status Code is 200\n",
      "['The Midnight Watch: A ...', 'The Lonely City: Adventures ...', 'The Gray Rhino: How ...', 'The Golden Condom: And ...', 'The Epidemic (The Program ...', 'The Dinner Party', 'The Diary of a ...', 'The Children', 'Stars Above (The Lunar ...', 'Snatched: How A Drug ...', 'Raspberry Pi Electronics Projects ...', 'Quench Your Own Thirst: ...', 'Psycho: Sanitarium (Psycho #1.5)', 'Poisonous (Max Revere Novels ...', 'One with You (Crossfire ...', 'No Love Allowed (Dodge ...', 'Murder at the 42nd ...', 'Most Wanted', 'Love, Lies and Spies', 'How to Speak Golf: ...']\n",
      "Response Status Code is 200\n",
      "['Hide Away (Eve Duncan ...', 'Furiously Happy: A Funny ...', 'Everyday Italian: 125 Simple ...', \"Equal Is Unfair: America's ...\", 'Eleanor & Park', 'Dirty (Dive Bar #1)', 'Can You Keep a ...', 'Boar Island (Anna Pigeon ...', 'A Paris Apartment', 'A la Mode: 120 ...', 'Troublemaker: Surviving Hollywood and ...', 'The Widow', 'The Sleep Revolution: Transforming ...', 'The Improbability of Love', 'The Art of Startup ...', 'Take Me Home Tonight ...', 'Sleeping Giants (Themis Files ...', 'Setting the World on ...', 'Playing with Fire', 'Off the Hook (Fishing ...']\n",
      "Response Status Code is 200\n",
      "['Mothering Sunday', 'Mother, Can You Not?', 'M Train', 'Lilac Girls', 'Lies and Other Acts ...', 'Lab Girl', 'Keep Me Posted', \"It Didn't Start with ...\", 'Grey (Fifty Shades #4)', 'Exit, Pursued by a ...', 'Daredevils', 'Cravings: Recipes for What ...', 'Born for This: How ...', 'Arena', 'Adultery', \"A Mother's Reckoning: Living ...\", \"A Gentleman's Position (Society ...\", '11/22/63', '10% Happier: How I ...', '10-Day Green Smoothie Cleanse: ...']\n",
      "Response Status Code is 200\n",
      "['Without Shame', 'Watchmen', 'Unlimited Intuition Now', 'Underlying Notes', 'The Shack', 'The New Brand You: ...', 'The Moosewood Cookbook: Recipes ...', 'The Flowers Lied', 'The Fabric of the ...', 'The Book of Mormon', 'The Art and Science ...', 'The Alien Club', 'Suzie Snowflake: One beautiful ...', 'Nap-a-Roo', 'NaNo What Now? Finding ...', 'Modern Day Fables', 'If I Gave You ...', 'Fruits Basket, Vol. 9 ...', 'Dress Your Family in ...', \"Don't Forget Steven\"]\n",
      "Response Status Code is 200\n",
      "['Chernobyl 01:23:40: The Incredible ...', 'Art and Fear: Observations ...', 'A Shard of Ice ...', \"A Hero's Curse (The ...\", '23 Degrees South: A ...', 'Zero to One: Notes ...', 'Why Not Me?', 'When Breath Becomes Air', 'Vagabonding: An Uncommon Guide ...', 'The Unlikely Pilgrimage of ...', 'The New Drawing on ...', 'The Midnight Assassin: Panic, ...', 'The Martian (The Martian ...', 'The High Mountains of ...', 'The Grownup', 'The E-Myth Revisited: Why ...', 'South of Sunshine', 'Smarter Faster Better: The ...', 'Silence in the Dark ...', 'Shadows of the Past ...']\n",
      "Response Status Code is 200\n",
      "['Roller Girl', 'Rising Strong', 'Proofs of God: Classical ...', 'Please Kill Me: The ...', 'Out of Print: City ...', 'My Life Next Door ...', \"Miller's Valley\", \"Man's Search for Meaning\", 'Love That Boy: What ...', 'Living Forward: A Proven ...', 'Les Fleurs du Mal', 'Left Behind (Left Behind ...', \"Kill 'Em and Leave: ...\", 'Kierkegaard: A Christian Missionary ...', 'John Vassos: Industrial Design ...', \"I'll Give You the ...\", 'I Will Find You', 'Hystopia: A Novel', 'Howl and Other Poems', 'History of Beauty']\n",
      "Response Status Code is 200\n",
      "['Heaven is for Real: ...', 'Future Shock (Future Shock ...', \"Ender's Game (The Ender ...\", 'Diary of a Citizen ...', 'Death by Leisure: A ...', 'Brilliant Beacons: A History ...', 'Brazen: The Courage to ...', 'Between the World and ...', 'Being Mortal: Medicine and ...', 'A Murder Over a ...', '32 Yolks', '\"Most Blessed of the ...', 'You Are a Badass: ...', 'Wildlife of New York: ...', 'What Happened on Beale ...', 'Unreasonable Hope: Finding Faith ...', 'Under the Tuscan Sun', \"Toddlers Are A**holes: It's ...\", 'The Year of Living ...', 'The Whale']\n",
      "Response Status Code is 200\n",
      "['The Story of Art', 'The Origin of Species', 'The Great Gatsby', 'The Good Girl', 'The Glass Castle', 'The Faith of Christopher ...', 'The Drowning Girls', 'The Constant Princess (The ...', 'The Bourne Identity (Jason ...', \"The Bachelor Girl's Guide ...\", 'The Art Book', 'The 7 Habits of ...', 'Team of Rivals: The ...', 'Steal Like an Artist: ...', 'Sit, Stay, Love', 'Sister Dear', 'Shrunken Treasures: Literary Classics, ...', 'Rich Dad, Poor Dad', 'Raymie Nightingale', 'Playing from the Heart']\n",
      "Response Status Code is 200\n",
      "['Nightstruck: A Novel', 'Naturally Lean: 125 Nourishing ...', 'Meternity', 'Memoirs of a Geisha', 'Like Never Before (Walker ...', 'Life of Pi', 'Leave This Song Behind: ...', \"King's Folly (The Kinsman ...\", 'John Adams', 'How to Cook Everything ...', 'How to Be a ...', 'Good in Bed (Cannie ...', 'Fruits Basket, Vol. 7 ...', 'For the Love: Fighting ...', 'Finding God in the ...', 'Every Heart a Doorway ...', 'Delivering the Truth (Quaker ...', 'Counted With the Stars ...', 'Chronicles, Vol. 1', 'Blue Like Jazz: Nonreligious ...']\n",
      "Response Status Code is 200\n",
      "['Benjamin Franklin: An American ...', 'At The Existentialist Café: ...', 'A Summer In Europe', 'A Short History of ...', 'A Gathering of Shadows ...', 'The Sound Of Love', 'The Rise and Fall ...', 'The Perks of Being ...', 'The Mysterious Affair at ...', 'The Man Who Mistook ...', 'The Makings of a ...', 'The Joy of Cooking', 'The Invention of Wings', 'The Hobbit (Middle-Earth Universe)', 'The Great Railway Bazaar', 'The Golden Compass (His ...', 'The God Delusion', 'The Girl You Left ...', 'The Fellowship of the ...', 'The Collected Poems of ...']\n",
      "Response Status Code is 200\n",
      "['The Barefoot Contessa Cookbook', \"Tell the Wolves I'm ...\", 'Ship Leaves Harbor: Essays ...', 'Pride and Prejudice', 'Musicophilia: Tales of Music ...', 'Mere Christianity', 'Me Before You (Me ...', 'In the Woods (Dublin ...', 'In Cold Blood', 'How to Stop Worrying ...', 'Give It Back', 'Girl, Interrupted', 'Fun Home: A Family ...', 'Fruits Basket, Vol. 6 ...', 'Deception Point', 'Death Note, Vol. 6: ...', 'Catherine the Great: Portrait ...', 'Better Homes and Gardens ...', 'An Unquiet Mind: A ...', 'A Year in Provence ...']\n",
      "Response Status Code is 200\n",
      "['World Without End (The ...', 'Will Grayson, Will Grayson ...', 'Why Save the Bankers?: ...', 'Where She Went (If ...', 'What If?: Serious Scientific ...', 'Two Summers', 'This Is Your Brain ...', 'The Secret Garden', 'The Raven King (The ...', 'The Raven Boys (The ...', 'The Power Greens Cookbook: ...', 'The Metamorphosis', 'The Mathews Men: Seven ...', 'The Little Paris Bookshop', 'The Hiding Place', 'The Grand Design', 'The Firm', 'The Fault in Our ...', 'The False Prince (The ...', 'The Expatriates']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['The Dream Thieves (The ...', 'The Darkest Corners', 'The Crossover', 'The 5th Wave (The ...', 'Tell the Wind and ...', 'Tell Me Three Things', 'Talking to Girls About ...', 'Siddhartha', 'Shiver (The Wolves of ...', 'Remember Me?', 'Red Dragon (Hannibal Lecter ...', 'Peak: Secrets from the ...', 'My Mother Was Nuts', 'Mexican Today: New and ...', 'Maybe Something Beautiful: How ...', 'Lola and the Boy ...', 'Logan Kade (Fallen Crest ...', 'Last One Home (New ...', 'Killing Floor (Jack Reacher ...', 'Kill the Boy Band']\n",
      "Response Status Code is 200\n",
      "['Isla and the Happily ...', 'If I Stay (If ...', 'I Know Why the ...', 'Harry Potter and the ...', 'Fruits Basket, Vol. 5 ...', 'Foundation (Foundation (Publication Order) ...', 'Fool Me Once', 'Find Her (Detective D.D. ...', 'Evicted: Poverty and Profit ...', 'Drama', 'Dracula the Un-Dead', 'Digital Fortress', 'Death Note, Vol. 5: ...', 'Data, A Love Story: ...', 'Critique of Pure Reason', 'Booked', 'Blue Lily, Lily Blue ...', 'Approval Junkie: Adventures in ...', 'An Abundance of Katherines', \"America's War for the ...\"]\n",
      "Response Status Code is 200\n",
      "['Alight (The Generations Trilogy ...', \"A Girl's Guide to ...\", 'A Game of Thrones ...', 'A Feast for Crows ...', 'A Clash of Kings ...', 'Vogue Colors A to ...', 'The Shining (The Shining ...', \"The Pilgrim's Progress\", 'The Perfect Play (Play ...', 'The Passion of Dolssa', 'The Jazz of Physics: ...', 'The Hunger Games (The ...', 'The Hound of the ...', 'The Gunning of America: ...', 'The Geography of Bliss: ...', 'The Demonists (Demonist #1)', 'The Demon Prince of ...', 'The Bone Hunters (Lexy ...', 'The Beast (Black Dagger ...', 'Some Women']\n",
      "Response Status Code is 200\n",
      "['Shopaholic Ties the Knot ...', 'Paper and Fire (The ...', 'Outlander (Outlander #1)', 'Orchestra of Exiles: The ...', 'No One Here Gets ...', 'Night Shift (Night Shift ...', 'Needful Things', 'Mockingjay (The Hunger Games ...', 'Misery', 'Little Women (Little Women ...', 'It', 'Harry Potter and the ...', 'Harry Potter and the ...', 'Harry Potter and the ...', 'Harry Potter and the ...', 'Harry Potter and the ...', 'Gone with the Wind', 'God Is Not Great: ...', 'Girl With a Pearl ...', 'Fruits Basket, Vol. 4 ...']\n",
      "Response Status Code is 200\n",
      "['Far From True (Promise ...', 'Dark Lover (Black Dagger ...', 'Confessions of a Shopaholic ...', 'Changing the Game (Play ...', 'Candide', 'Can You Keep a ...', 'Atlas Shrugged', 'Animal Farm', 'A Walk to Remember', 'A New Earth: Awakening ...', 'A History of God: ...', \"'Salem's Lot\", 'Zero History (Blue Ant ...', 'Wuthering Heights', 'World War Z: An ...', 'Wild: From Lost to ...', \"Where'd You Go, Bernadette\", 'When You Are Engulfed ...', 'We the People: The ...', 'We Are All Completely ...']\n",
      "Response Status Code is 200\n",
      "['Walk the Edge (Thunder ...', 'Voyager (Outlander #3)', 'Very Good Lives: The ...', 'Vegan Vegetarian Omnivore: Dinner ...', 'Unstuffed: Decluttering Your Home, ...', 'Under the Banner of ...', 'Two Boys Kissing', 'Twilight (Twilight #1)', 'Twenties Girl', 'Trespassing Across America: One ...', 'Three-Martini Lunch', 'Thinking, Fast and Slow', 'The Wild Robot', 'The Wicked + The ...', 'The Undomestic Goddess', 'The Travelers', 'The Tipping Point: How ...', 'The Thing About Jellyfish', 'The Stand', 'The Smitten Kitchen Cookbook']\n",
      "Response Status Code is 200\n",
      "['The Silkworm (Cormoran Strike ...', 'The Sandman, Vol. 3: ...', 'The Rose & the ...', 'The Road to Little ...', 'The Rise of Theodore ...', 'The Restaurant at the ...', 'The Rest Is Noise: ...', 'The Red Tent', 'The Purpose Driven Life: ...', 'The Purest Hook (Second ...', 'The Picture of Dorian ...', 'The Paris Wife', 'The Obsession', 'The Nightingale', 'The New Guy (and ...', 'The Nanny Diaries (Nanny ...', 'The Name of God ...', 'The Maze Runner (The ...', \"The Lover's Dictionary\", 'The Lonely Ones']\n",
      "Response Status Code is 200\n",
      "['The Lean Startup: How ...', 'The Last Painting of ...', 'The Land of 10,000 ...', 'The Infinities', \"The Husband's Secret\", \"The Hitchhiker's Guide to ...\", 'The Guns of August', 'The Guernsey Literary and ...', 'The Goldfinch', 'The Giver (The Giver ...', 'The Girl with All ...', 'The Girl Who Played ...', 'The Girl Who Kicked ...', 'The Exiled', 'The End of Faith: ...', 'The Elegant Universe: Superstrings, ...', 'The Disappearing Spoon: And ...', 'The Devil Wears Prada ...', 'The Demon-Haunted World: Science ...', 'The Day the Crayons ...']\n",
      "Response Status Code is 200\n",
      "['The Da Vinci Code ...', \"The Cuckoo's Calling (Cormoran ...\", 'The Complete Stories and ...', 'The Complete Poems', 'The Catcher in the ...', 'The Cat in the ...', 'The Case for Christ ...', 'The Book Thief', 'The Book of Basketball: ...', 'The Blind Side: Evolution ...', 'The Autobiography of Malcolm ...', 'The Art of Simple ...', 'The Art of Fielding', \"Surely You're Joking, Mr. ...\", 'Stiff: The Curious Lives ...', 'Spilled Milk: Based on ...', 'Something Borrowed (Darcy & ...', 'Something Blue (Darcy & ...', 'Soldier (Talon #3)', 'Shopaholic & Baby (Shopaholic ...']\n",
      "Response Status Code is 200\n",
      "['Seven Days in the ...', 'Seven Brief Lessons on ...', 'Scarlet (The Lunar Chronicles ...', \"Sarah's Key\", 'Saga, Volume 3 (Saga ...', 'Running with Scissors', 'Rogue Lawyer (Rogue Lawyer ...', 'Rise of the Rocket ...', 'Rework', 'Reservations for Two', 'Red: The True Story ...', 'Ready Player One', 'Quiet: The Power of ...', 'Prodigy: The Graphic Novel ...', 'Persepolis: The Story of ...', 'Packing for Mars: The ...', 'Outliers: The Story of ...', 'Original Fake', 'Orange Is the New ...', 'One for the Money ...']\n",
      "Response Status Code is 200\n",
      "['Notes from a Small ...', 'Night (The Night Trilogy ...', 'Neither Here nor There: ...', 'Naked', 'Morning Star (Red Rising ...', 'Miracles from Heaven: A ...', 'Midnight Riot (Peter Grant/ ...', 'Me Talk Pretty One ...', 'Manuscript Found in Accra', 'Lust & Wonder', 'Lila (Gilead #3)', 'Life, the Universe and ...', 'Life Without a Recipe', 'Life After Life', 'Letter to a Christian ...', \"Let's Pretend This Never ...\", 'Legend (Legend #1)', 'Lean In: Women, Work, ...', 'Lamb: The Gospel According ...', 'Lady Renegades (Rebel Belle ...']\n",
      "Response Status Code is 200\n",
      "['Jurassic Park (Jurassic Park ...', \"It's Never Too Late ...\", 'Is Everyone Hanging Out ...', 'Into the Wild', 'Inferno (Robert Langdon #4)', 'In the Garden of ...', 'If I Run (If ...', \"I've Got Your Number\", 'I Am Malala: The ...', 'Hungry Girl Clean & ...', 'House of Lost Worlds: ...', 'House of Leaves', 'Horrible Bear!', 'Holidays on Ice', 'Heir to the Sky', 'Green Eggs and Ham ...', 'Grayson, Vol 3: Nemesis ...', 'Gratitude', 'Gone Girl', 'Golden (Heart of Dread ...']\n",
      "Response Status Code is 200\n",
      "['Girl in the Blue ...', 'Fruits Basket, Vol. 3 ...', 'Friday Night Lights: A ...', 'Fire Bound (Sea Haven/Sisters ...', 'Fifty Shades Freed (Fifty ...', 'Fellside', 'Extreme Prey (Lucas Davenport ...', 'Eragon (The Inheritance Cycle ...', 'Eclipse (Twilight #3)', 'Dune (Dune #1)', 'Dracula', 'Do Androids Dream of ...', 'Disrupted: My Misadventure in ...', 'Dead Wake: The Last ...', 'David and Goliath: Underdogs, ...', 'Darkfever (Fever #1)', 'Dark Places', 'Crazy Rich Asians (Crazy ...', 'Counting Thyme', 'Cosmos']\n",
      "Response Status Code is 200\n",
      "['Civilization and Its Discontents', 'Cinder (The Lunar Chronicles ...', 'Catastrophic Happiness: Finding Joy ...', 'Career of Evil (Cormoran ...', 'Breaking Dawn (Twilight #4)', 'Brave Enough', 'Boy Meets Boy', 'Born to Run: A ...', 'Blink: The Power of ...', 'Black Flags: The Rise ...', 'Black Butler, Vol. 1 ...', 'Big Little Lies', 'Between Shades of Gray', 'Best of My Love ...', 'Beowulf', 'Beautiful Creatures (Caster Chronicles ...', 'Awkward', 'Ash', 'Are We There Yet?', 'Are We Smart Enough ...']\n",
      "Response Status Code is 200\n",
      "['Annie on My Mind', 'And Then There Were ...', 'A Walk in the ...', 'A Visit from the ...', 'A Storm of Swords ...', 'A Heartbreaking Work of ...', '8 Keys to Mental ...', '#GIRLBOSS', 'The Suffragettes (Little Black ...', 'The Sense of an ...', 'The Sandman, Vol. 2: ...', 'The Course of Love', 'Sugar Rush (Offensive Line ...', 'Saga, Volume 2 (Saga ...', 'Run, Spot, Run: The ...', 'New Moon (Twilight #2)', 'Life', \"Kindle Paperwhite User's Guide\", 'H is for Hawk', 'Girl Online On Tour ...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code is 200\n",
      "['Fruits Basket, Vol. 2 ...', 'Diary of a Minecraft ...', 'Y: The Last Man, ...', 'While You Were Mine', 'Where Lightning Strikes (Bleeding ...', \"When I'm Gone\", 'Ways of Seeing', 'Vampire Knight, Vol. 1 ...', 'Vampire Girl (Vampire Girl ...', 'Twenty Love Poems and ...', 'Travels with Charley: In ...', 'Three Wishes (River of ...', 'This One Moment (Pushing ...', 'The Zombie Room', 'The Wicked + The ...', 'The Tumor', 'The Story of Hong ...', 'The Silent Wife', 'The Silent Twin (Detective ...', 'The Selfish Gene']\n",
      "Response Status Code is 200\n",
      "['The Secret Healer', 'The Sandman, Vol. 1: ...', 'The Republic', 'The Odyssey', \"The No. 1 Ladies' ...\", 'The Nicomachean Ethics', 'The Name of the ...', 'The Mirror & the ...', 'The Little Prince', 'The Light of the ...', 'The Last Girl (The ...', 'The Iliad', 'The Hook Up (Game ...', 'The Haters', 'The Girl You Lost', 'The Girl In The ...', 'The End of the ...', 'The Edge of Reason ...', 'The Complete Maus (Maus ...', 'The Communist Manifesto']\n",
      "Response Status Code is 200\n",
      "['The Bhagavad Gita', 'The Bette Davis Club', 'The Art of Not ...', 'Taking Shots (Assassins #1)', 'Starlark', 'Skip Beat!, Vol. 01 ...', 'Sister Sable (The Mad ...', 'Shatter Me (Shatter Me ...', 'Shameless', 'Shadow Rites (Jane Yellowrock ...', 'Settling the Score (The ...', 'Sense and Sensibility', 'Saga, Volume 1 (Saga ...', 'Rhythm, Chord & Malykhin', 'Rat Queens, Vol. 1: ...', 'Paradise Lost (Paradise #1)', 'Paper Girls, Vol. 1 ...', 'Ouran High School Host ...', 'Origins (Alphas 0.5)', 'One Second (Seven #7)']\n",
      "Response Status Code is 200\n",
      "['On the Road (Duluoz ...', 'Old Records Never Die: ...', 'Off Sides (Off #1)', 'Of Mice and Men', 'Myriad (Prentor #1)', 'My Perfect Mistake (Over ...', 'Ms. Marvel, Vol. 1: ...', 'Meditations', 'Matilda', 'Lost Among the Living', 'Lord of the Flies', 'Listen to Me (Fusion ...', 'Kitchens of the Great ...', 'Jane Eyre', 'Imperfect Harmony', 'Icing (Aces Hockey #2)', 'Hawkeye, Vol. 1: My ...', \"Having the Barbarian's Baby ...\", 'Giant Days, Vol. 1 ...', 'Fruits Basket, Vol. 1 ...']\n",
      "Response Status Code is 200\n",
      "['Frankenstein', 'Forever Rockers (The Rocker ...', 'Fighting Fate (Fighting #6)', 'Emma', 'Eat, Pray, Love', 'Deep Under (Walker Security ...', 'Choosing Our Religion: The ...', 'Charlie and the Chocolate ...', \"Charity's Cross (Charles Towne ...\", 'Bright Lines', \"Bridget Jones's Diary (Bridget ...\", 'Bounty (Colorado Mountain #7)', 'Blood Defense (Samantha Brinkman ...', 'Bleach, Vol. 1: Strawberry ...', 'Beyond Good and Evil', \"Alice in Wonderland (Alice's ...\", 'Ajin: Demi-Human, Volume 1 ...', \"A Spy's Devotion (The ...\", \"1st to Die (Women's ...\", '1,000 Places to See ...']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "    \n",
    "    def my_booktitle_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        table_content = soup.find('div', {'class':'col-sm-8 col-md-9'})\n",
    "        return [element.text for element in table_content.find_all('h3')]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    # CHALLENGE 3 - integrate a sleep timer\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            if self.sleep_interval > 0: \n",
    "                sleep(sleep_interval) # do I need to pass 'self.sleep_interval' as the argument instead?\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "# URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "# PAGES_TO_SCRAPE = 10 # how many webpages to scrape, updated for CHALLENGE 4\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html'\n",
    "PAGES_TO_SCRAPE = 50 # 1,000 results, at 20 per page, gives 50 pages \n",
    "    \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_booktitle_parser)\n",
    "my_spider.kickstart() # part of this function prints itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Making Your Spider Unblockable\n",
    "\n",
    "Use techniques such as randomizing user agents and referers in your requests to reduce the likelihood that your spider is blocked by websites. [Here](http://blog.adnansiddiqi.me/5-strategies-to-write-unblock-able-web-scrapers-in-python/) is a great article to learn these techniques.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the reference material, I typed \"what is my user agent\" into google, returned\n",
    "'''\n",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\n",
    "\n",
    "paste that to give this\n",
    "my_header = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'\n",
    "          }\n",
    "which can then be passed as an optional argument to the requests.get() function\n",
    "response = requests.get(url, headers = 'my_header')\n",
    "'''\n",
    "\n",
    "# a function from the reference material on making a random user-agent selection\n",
    "import numpy as np\n",
    " \n",
    "def get_random_ua():\n",
    "    random_ua = '' # call it an empty string\n",
    "    ua_file = 'ua_file.txt' # label the destination, typically a text file that holds a bunch of user agents (put this file in the .gitignore)\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines() # try to open the file, reading all the lines within \n",
    "        if len(lines) > 0: # if something exists within this, if you successfully read the lines from the file\n",
    "            prng = np.random.RandomState() # this is a random number generator\n",
    "            index = prng.permutation(len(lines) - 1) # pick a random number within\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)] # assign the data from that randomly selected line\n",
    "    except Exception as ex: # unless things went wrong\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here # not entirely sure if this works\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None, HEADERS):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "        self.headers = headers\n",
    "    \n",
    "    # BONUS 1 - get a random User Agent\n",
    "    def get_random_ua():\n",
    "        random_ua = '' # call it an empty string\n",
    "        ua_file = 'ua_file.txt' # label the destination, typically a text file that holds a bunch of user agents (put this file in the .gitignore)\n",
    "        try:\n",
    "            with open(ua_file) as f:\n",
    "                lines = f.readlines() # try to open the file, reading all the lines within \n",
    "            if len(lines) > 0: # if something exists within this, if you successfully read the lines from the file\n",
    "                prng = np.random.RandomState() # this is a random number generator\n",
    "                index = prng.permutation(len(lines) - 1) # pick a random number within\n",
    "                idx = np.asarray(index, dtype=np.integer)[0]\n",
    "                random_ua = lines[int(idx)] # assign the data from that randomly selected line\n",
    "        except Exception as ex: # unless things went wrong\n",
    "            print('Exception in random_ua')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return random_ua\n",
    "    \n",
    "    def get_referrer():\n",
    "        referral_link = ''\n",
    "        ref_file = 'ref_file.txt'\n",
    "        try:\n",
    "            with open(ref_file) as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) > 0:\n",
    "                prng = np.random.RandomState()\n",
    "                index = prng.permutation(len(lines) - 1)\n",
    "                idx = np.asarray(index, dtype=np.integer)[0]\n",
    "                referral_link = lines[int(idx)]\n",
    "        except Exception as err:\n",
    "            print(\"Exception in referral_link\")\n",
    "            print(str(err))\n",
    "        finally:\n",
    "            return referall_link\n",
    "        \n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10, headers = HEADERS)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "    \n",
    "    def my_booktitle_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        table_content = soup.find('div', {'class':'col-sm-8 col-md-9'})\n",
    "        return [element.text for element in table_content.find_all('h3')]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    # CHALLENGE 3 - integrate a sleep timer\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            if self.sleep_interval > 0: \n",
    "                sleep(sleep_interval) # do I need to pass 'self.sleep_interval' as the argument instead?\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "# URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "# PAGES_TO_SCRAPE = 10 # how many webpages to scrape, updated for CHALLENGE 4\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html'\n",
    "PAGES_TO_SCRAPE = 50 # 1,000 results, at 20 per page, gives 50 pages \n",
    "HEADERS = {'user-agent' = get_random_ua(), 'referrer' = get_referrer()}   \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_booktitle_parser, HEADERS)\n",
    "my_spider.kickstart() # part of this function prints itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Making Asynchronous Calls\n",
    "\n",
    "Implement asynchronous calls to `IronhackSpider`. You will make requests in parallel to complete your tasks faster.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# DEPENDENCIES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import asyncio\n",
    "\n",
    "class IronhackSpider:\n",
    "    # initalize the class, with the arguments that are passed within\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None, HEADERS):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "        self.headers = headers\n",
    "    \n",
    "    # BONUS 1 - get a random User Agent\n",
    "    def get_random_ua():\n",
    "        random_ua = '' # call it an empty string\n",
    "        ua_file = 'ua_file.txt' # label the destination, typically a text file that holds a bunch of user agents (put this file in the .gitignore)\n",
    "        try:\n",
    "            with open(ua_file) as f:\n",
    "                lines = f.readlines() # try to open the file, reading all the lines within \n",
    "            if len(lines) > 0: # if something exists within this, if you successfully read the lines from the file\n",
    "                prng = np.random.RandomState() # this is a random number generator\n",
    "                index = prng.permutation(len(lines) - 1) # pick a random number within\n",
    "                idx = np.asarray(index, dtype=np.integer)[0]\n",
    "                random_ua = lines[int(idx)] # assign the data from that randomly selected line\n",
    "        except Exception as ex: # unless things went wrong\n",
    "            print('Exception in random_ua')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return random_ua\n",
    "    \n",
    "    def get_referrer():\n",
    "        referral_link = ''\n",
    "        ref_file = 'ref_file.txt'\n",
    "        try:\n",
    "            with open(ref_file) as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) > 0:\n",
    "                prng = np.random.RandomState()\n",
    "                index = prng.permutation(len(lines) - 1)\n",
    "                idx = np.asarray(index, dtype=np.integer)[0]\n",
    "                referral_link = lines[int(idx)]\n",
    "        except Exception as err:\n",
    "            print(\"Exception in referral_link\")\n",
    "            print(str(err))\n",
    "        finally:\n",
    "            return referall_link\n",
    "    \n",
    "    # CHALLENGE 2 this function scrapes the url, parses the content inside, and handles\n",
    "    def scrape_url(self, url):\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10, headers = HEADERS)\n",
    "            print(\"Response Status Code is \" + str(response.status_code))\n",
    "            if response.status_code >= 300:\n",
    "                print(\"Got an error: \" + str(response.status_code))\n",
    "        except requests.exceptions.Timeout as Terr:\n",
    "            print(\"Timed out after over 10 seconds \" + str(Terr))\n",
    "            pass\n",
    "        except requests.exceptions.TooManyRedirects as Rerr:\n",
    "            print(\"Tried to redirect you too many times \" + str(Rerr))\n",
    "            pass\n",
    "        except requests.exceptions.SSLError as SSLerr:\n",
    "            print(\"This site is not secure \" + str(SSLerr))\n",
    "            pass\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error \" + str(e))\n",
    "        \n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    # used for scrape_url() to find all the quote content\n",
    "    def my_quotes_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        return [element.text for element in soup.find_all('span', {'class':'text'})]\n",
    "    \n",
    "    def my_booktitle_parser(site):\n",
    "        soup = bs(site, \"html.parser\")\n",
    "        table_content = soup.find('div', {'class':'col-sm-8 col-md-9'})\n",
    "        return [element.text for element in table_content.find_all('h3')]\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    # CHALLENGE 3 - integrate a sleep timer\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            if self.sleep_interval > 0: \n",
    "                sleep(sleep_interval) # do I need to pass 'self.sleep_interval' as the argument instead?\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "      \n",
    "\n",
    "# URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "# PAGES_TO_SCRAPE = 10 # how many webpages to scrape, updated for CHALLENGE 4\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html'\n",
    "PAGES_TO_SCRAPE = 50 # 1,000 results, at 20 per page, gives 50 pages \n",
    "HEADERS = {'user-agent' = get_random_ua(), 'referrer' = get_referrer()}   \n",
    "    \n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=IronhackSpider.my_booktitle_parser, HEADERS)\n",
    "my_spider.kickstart() # part of this function prints itself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
