![Ironhack logo](https://i.imgur.com/1QgrNNw.png)

# Lab | Supervised Learning Model Evaluation

## Introduction

You have already been familiar with the complete ML pipelines (both supervised and unsupervised) by conducting past labs. However, every dataset is different and as your experience grows you are able to choose better solutions in different scenarios. Therefore, keep practicing with all the datasets you can find as much as you can.

Linear regression model is not the silver bullet for all supervised learning analysis. In this lab we will present you a problem scenario where different supervised learning models are more appropriate. You will conduct a complete supervised learning analysis, apply different models, and compare their performances.

## Getting Started

Open the `main.ipynb` file in the `your-code` directory. Follow the instructions and add your code and explanations as necessary. At the end, in addition to completing the cells please also save your RF model as a pickle file.

## Deliverables

- `main.ipynb` with your responses.
- *mushroom.sav* file of your RF model.

## Submission

Upon completion, add your deliverables to git. Then commit git and push your branch to the remote.

## Resources

[Mushroom Data Set @UCI MLP](https://archive.ics.uci.edu/ml/datasets/mushroom)

[Mushroom Classification @Kaggle](https://www.kaggle.com/uciml/mushroom-classification)

[Consequences of multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity#Consequences_of_multicollinearity)

[Chi-Square Test of Independence](https://onlinecourses.science.psu.edu/stat500/node/56/)

[pandas.crosstab](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html)

[scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.chi2_contingency.html)

[pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)

[sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

[Random Forest](https://en.wikipedia.org/wiki/Random_forest)

[Bagging and Random Forests](https://onlinecourses.science.psu.edu/stat857/node/179/)

[Support Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine)

[sklearn.ensemble.RandomForestClassifier]([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))

[Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)

[sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

[Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)

[sklearn.ensemble.GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)

[pickle - Python object serialization](https://docs.python.org/3/library/pickle.html)

[Analysis and /classification of Mushrooms](https://www.kaggle.com/haimfeld87/analysis-and-classification-of-mushrooms)

[The Search for Categorical Correlation](https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9)
